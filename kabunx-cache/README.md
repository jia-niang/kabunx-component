## 缓存

简单的理解，缓存就是将数据从读取较慢的介质上读取出来放到读取较快的介质上，如磁盘-->
内存。平时我们会将数据存储到磁盘上，如：数据库。如果每次都从数据库里去读取，会因为磁盘本身的 IO 影响读取速度，所以就有了像
redis 这种的内存缓存。可以将数据读取出来放到内存里，这样当需要获取数据时，就能够直接从内存中拿到数据返回，能够很大程度的提高速度。

## 为什么使用缓存

在高并发、大流量等场景下，降低系统延迟，缓解数据库压力，提高系统整体的性能，让用户有更好的体验。

## 使用场景

读多写少、不追求强一致性、请求入参不易变化。

## 现状

目前缓存的解决方案一般有两种：

* 内存缓存（如 Caffeine） —— 速度快，进程内可用
* 集中式缓存（如 Redis）—— 可同时为多节点提供服务

现有的缓存框架已经非常成熟而且优秀，那为什么还需要使用二级缓存呐？主要解决以下几个问题：

* 使用内存缓存时，一旦应用重启后，由于缓存数据丢失，缓存雪崩，给数据库造成巨大压力，导致应用堵塞
* 使用内存缓存时，多个应用节点无法共享缓存数据
* 使用集中式缓存，由于大量的数据通过缓存获取，导致缓存服务的数据吞吐量太大，带宽跑满。现象就是 Redis
  服务负载不高，但是由于机器网卡带宽跑满，导致数据读取非常慢

在遭遇问题 1、2 时，很多人自然而然会想到使用 Redis 来缓存数据，因此就难以避免的导致了问题 3 的发生。

当发生问题 3 时，又有很多人想到 Redis 的集群，通过集群来降低缓存服务的压力，特别是带宽压力。

但其实，这个时候的 Redis 上的数据量并不一定大，仅仅是数据的吞吐量大而已。

综合所述：我们需要构建 L1 Caffeine JVM 级别内存 ， L2 Redis 内存。

## 思考

L2Cache 缓存系统其实不是一个缓存框架，它更像是一个缓存框架的桥梁。它利用现有优秀的内存缓存框架作为一级缓存，而把 Redis
作为二级缓存。所有数据的读取先从一级缓存中读取，不存在时再从二级缓存读取，这样来确保对二级缓存 Redis 的访问次数降到最低。

有人会质疑说，那岂不是应用节点的内存占用要飙升？我的答案是 ——
现在服务器的内存已经非常便宜了，这点点的内存消耗完全不在话下。其次一级缓存框架可以通过配置来控制在内存中存储的数据量，所以不用担心内存溢出的问题。

剩下的另外一个问题就是，当缓存数据更新的时候，怎么确保每个节点内存中的数据是一致的。这恰恰是设计的核心所在。

目前提供两种节点间数据同步的方案 —— Redis Pub/Sub。当某个节点的缓存数据需要更新时，L2Cache 会通过 Redis
的消息订阅机制来通知集群内其他节点。当其他节点收到缓存数据更新的通知时，它会清掉自己内存里的数据，然后重新从
Redis 中读取最新数据。

## 现有技术

| 方案          | 支持度 | 实现难度 | 可维护性 | 可扩展性 | 潜在问题                  |
|-------------|-----|------|------|------|-----------------------|
| SpringCache | 低   | 中    | 易    | 高    | 需要自己扩展                |
| JetCache    | 高   | 中    | 易    | 中    | 不满足多租户                |
| J2Cache     | 中   | 中    | 易    | 中    | 集成到 SpringBoot，不满足多租户 |

### Spring Cache

spring cache 是 spring-context 包中提供的基于注解方式使用的缓存组件，定义了一些标准接口，通过实现这些接口，就可以通过在方法上增加注解来实现缓存。这样就能够避免缓存代码与业务处理耦合在一起的问题。spring
cache 的实现是使用 spring aop 中对方法切面（MethodInterceptor）封装的扩展，当然 spring aop 也是基于 Aspect 来实现的。

目前大部分应用缓存都是基于 Spring Cache 实现,基于注释（annotation）的缓存（cache）技术,存在的问题如下：

* Spring Cache 仅支持 单一的缓存来源，即：只能选择 Redis 实现或者 Caffeine 实现，并不能同时使用。
* 数据一致性：各层缓存之间的数据一致性问题，如应用层缓存和分布式缓存之前的数据一致性问题。
* 缓存过期：Spring Cache 不支持主动的过期策略
* cacheNullValues 默认为false 存在缓存穿透的风险，注意这个属性是被 final 修饰的。

## JetCache

### 简介

JetCache 是一个基于 Java 的缓存系统封装，提供统一的 API 和注解来简化缓存的使用。
JetCache 提供了比 SpringCache 更加强大的注解，可以原生的支持 TTL、两级缓存、分布式自动刷新，还提供了 Cache 接口用于手工缓存操作。
当前有四个实现：RedisCache、RedisLettuceCache、CaffeineCache、LinkedHashMapCache。

JetCache提供的核心能力包括：

* 提供统一的，类似 jsr-107 风格的 API 访问 Cache，并可通过注解创建并配置 Cache 实例
* 通过注解实现声明式的方法缓存，支持 TTL 和两级缓存
* 分布式缓存自动刷新，分布式锁 (2.2+)
* 分布式多级缓存场景，缓存更新后，自动让所有的 local cache 失效（2.7+）
* 支持异步 Cache API
* Spring Boot 支持
* Key 的生成策略和 Value 的序列化策略是可以定制的
* 针对所有 Cache 实例和方法缓存的自动统计

自动刷新和加载保护是 JetCache 的大杀器，对于加载开销比较大的对象，为了防止缓存未命中时的高并发访问打爆数据库。

## 补充知识

### 缓存优化的一般思路

一般，缓存针对的主要是读操作。当你的功能遇到下面的场景时，就可以选择使用缓存组件进行性能优化：

* 存在数据热点，缓存的数据能够被频繁使用；
* 读操作明显比写操作要多；
* 下游功能存在着比较悬殊的性能差异，下游服务能力有限；
* 加入缓存以后，不会影响程序的正确性，或者引入不可预料的复杂性。

缓存组件和缓冲类似，也是在两个组件速度严重不匹配的时候，引入的一个中间层，但它们服务的目标是不同的：

* 缓冲，数据一般只使用一次，等待缓冲区满了，就执行 flush 操作；
* 缓存，数据被载入之后，可以多次使用，数据将会共享多次。

缓存最重要的指标就是命中率，有以下几个因素会影响命中率。

（1）缓存容量

缓存的容量总是有限制的，所以就存在一些冷数据的逐出问题。但缓存也不是越大越好，它不能明显挤占业务的内存。

（2）数据集类型

如果缓存的数据是非热点数据，或者是操作几次就不再使用的冷数据，那命中率肯定会低，缓存也会失去了它的作用。

（3）缓存失效策略

缓存算法也会影响命中率和性能，目前效率最高的算法是 Caffeine 使用的 W-TinyLFU 算法，它的命中率非常高，内存占用也更小。新版本的
spring-cache，已经默认支持 Caffeine。

一般来说：

* 缓存命中率达到 50% 以上，作用就开始变得显著；
* 缓存命中率低于 10%，那就需要考虑缓存组件的必要性了。

引入缓存组件，能够显著提升系统性能，但也会引入新的问题。如何保证缓存与源数据的同步这个是高频问题。

### 缓存一致性

对于一个缓存项来说，常用的操作有四个：写入、更新、读取、删除。

* 写入：缓存和数据库是两个不同的组件，只要涉及双写，就存在只有一个写成功的可能性，造成数据不一致。
* 更新：更新的情况类似，需要更新两个不同的组件。
* 读取：读取要保证从缓存中读到的信息是最新的，是和数据库中的是一致的。
* 删除：当删除数据库记录的时候，如何把缓存中的数据也删掉？

一般推荐使用触发式的缓存一致性方式，使用懒加载的方式，可以让缓存的同步变得非常简单：

* 当读取缓存的时候，如果缓存里没有相关数据，则执行相关的业务逻辑，构造缓存数据存入到缓存系统；
* 当与缓存项相关的资源有变动，则先删除相应的缓存项，然后再对资源进行更新，这个时候，即使是资源更新失败，也是没有问题的。

但这样有一个问题，缓存删除动作，和数据库的更新动作，明显是不在一个事务里的。
如果一个请求删除缓存，还未更新数据库的时候，同时另一请求到达，发现没有缓存，就从数据库里加载了一份到缓存系统。
接下来更新数据库才完成，这时候数据库和缓存的内容，就产生了不一致。

可以使用分布式锁来解决这个问题，将缓存操作和数据库删除操作，与其他的缓存读操作，使用锁进行资源隔离即可。一般来说，读操作是不需要加锁的，它会在遇到锁的时候，重试等待，直到超时。



